<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agent reasoning | Prof. Sebastian Sardina</title>
    <link>https://ssardina.github.io/tag/agent-reasoning/</link>
      <atom:link href="https://ssardina.github.io/tag/agent-reasoning/index.xml" rel="self" type="application/rss+xml" />
    <description>Agent reasoning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2022</copyright><lastBuildDate>Sun, 16 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ssardina.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Agent reasoning</title>
      <link>https://ssardina.github.io/tag/agent-reasoning/</link>
    </image>
    
    <item>
      <title>Goal-Intention Recognition</title>
      <link>https://ssardina.github.io/project/gr/</link>
      <pubDate>Sun, 16 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ssardina.github.io/project/gr/</guid>
      <description>&lt;p&gt;The goal/intention recognition problem is the task of identifying an agent’s intent by observing its behaviour. Traditionally, the problem has involved matching a sequence of observations to a plan in a pre-defined plan library; the winning plan being the one that &amp;ldquo;best&amp;rdquo; matches the observations.&lt;/p&gt;
&lt;p&gt;Recent developments dispense with the overhead of a plan library and instead&amp;mdash;based on the assumption that the observed agent is behaving rationally&amp;mdash;take a cost-based approach and uses classical planning technology to generate candidate plans as needed over a domain model.&lt;/p&gt;
&lt;p&gt;In a series of work, we have extended and improved the cost-based approach to goal recognition, both for general task planning and path planning. We have worked on how to make recognition faster and more robust to irrational/erratic observed behavior. We have also looked at its&#39; dual problem: &lt;em&gt;deceptive behavior&lt;/em&gt;, the problem of generating behavior that is as deceptive as possible, while still achieving the intended objective.&lt;/p&gt;
&lt;p&gt;Some representative papers are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Peta Masters, Sebastian Sardiña: 
&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0004370221000412?via%3Dihub&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Expecting the unexpected: Goal recognition for rational and irrational agents&lt;/a&gt;. Artificial Intelligence. 297: 103490 (2021)&lt;/li&gt;
&lt;li&gt;Artem Polyvyanyy, Zihang Su, Nir Lipovetzky, Sebastian Sardiña: 
&lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3398761.3398886&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Goal Recognition Using Off-The-Shelf Process Mining Techniques&lt;/a&gt;. AAMAS 2020: 1072-1080&lt;/li&gt;
&lt;li&gt;Peta Masters, Sebastian Sardiña: 
&lt;a href=&#34;https://jair.org/index.php/jair/article/view/11343&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cost-Based Goal Recognition in Navigational Domains&lt;/a&gt;. Journal Artificial Intelligence Research 64: 197-242 (2019)&lt;/li&gt;
&lt;li&gt;Peta Masters, Sebastian Sardiña: 
&lt;a href=&#34;https://www.ijcai.org/proceedings/2017/610&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deceptive Path-Planning&lt;/a&gt;. IJCAI 2017: 4368-4375.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
